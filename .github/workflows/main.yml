name: Update Comprehensive SRS

on:
  workflow_dispatch:
  schedule:
    - cron: '0 20 * * *' 
  push:
    paths:
      - 'fakeip-filter-Remote-DNS.json'
      - '.github/workflows/**'

jobs:
  build:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Install Dependencies
        run: pip install dnspython requests

      - name: Install sing-box
        run: |
          LATEST_TAG=$(curl -s "https://api.github.com/repos/SagerNet/sing-box/releases/latest" | grep -Po '"tag_name": "\K.*?(?=")')
          VERSION_NUM=${LATEST_TAG#v}
          curl -Lo sing-box.tar.gz "https://github.com/SagerNet/sing-box/releases/download/${LATEST_TAG}/sing-box-${VERSION_NUM}-linux-amd64.tar.gz"
          tar -xvf sing-box.tar.gz
          mv sing-box-*/sing-box .
          chmod +x sing-box

      - name: Advanced Consensus Merge & Smart Classification
        run: |
          # ä¸‹è½½æº
          curl -sL "https://raw.githubusercontent.com/77160860/rule/refs/heads/main/filter.json" -o s1.json
          curl -sL "https://github.com/DustinWin/ruleset_geodata/releases/download/sing-box-ruleset/fakeip-filter.srs" -o s2.srs
          ./sing-box rule-set decompile s2.srs -o s2.json
          curl -sL "https://raw.githubusercontent.com/HenryChiao/mihomo_yamls/refs/heads/main/custom/domain/fake-ip-filter.list" -o s3.list
          
          # ä¸‹è½½åˆ†æµè¾…åŠ©æ•°æ®
          curl -sL "https://raw.githubusercontent.com/misakaio/chnroutes2/master/chnroutes.txt" -o chnroutes.txt
          curl -sL "https://raw.githubusercontent.com/MetaCubeX/meta-rules-dat/sing/geo/geosite/cn.json" -o geosite-cn.json

          python3 -c "
          import json, re, os, dns.resolver, ipaddress, concurrent.futures

          # --- 1. é…ç½®ä¸èµ„æºåŠ è½½ ---
          registry = {}
          LAN_SUFFIXES = {'.lan', '.local', '.home.arpa', '.internal', '.localdomain', 'localhost'}
          CN_NETWORKS = [ipaddress.ip_network(l.strip()) for l in open('chnroutes.txt') if l.strip() and not l.startswith('#')]
          
          CN_GEOSITE = set()
          try:
              with open('geosite-cn.json', 'r') as f:
                  g = json.load(f)
                  for r in g.get('rules', []):
                      for k in ['domain', 'domain_suffix']:
                          for d in r.get(k, []): CN_GEOSITE.add(d.lower())
          except: pass

          resolver = dns.resolver.Resolver()
          resolver.nameservers = ['8.8.8.8', '1.1.1.1']
          resolver.timeout = 1.5

          # --- 2. æ³¨å†Œå‡½æ•° (å¸¦ç±»å‹) ---
          def register(val, r_type, source_id):
              val = val.strip().lower()
              if not val or len(val) < 3 or ' ' in val: return
              if any(val.endswith(s) or val == s.strip('.') for s in LAN_SUFFIXES): return
              if val not in registry: registry[val] = {'sources': set(), 'types': set()}
              registry[val]['sources'].add(source_id)
              registry[val]['types'].add(r_type)

          # åŠ è½½æºé€»è¾‘
          def load_json(path, sid):
              if not os.path.exists(path): return
              with open(path, 'r') as f:
                  d = json.load(f)
                  for r in d.get('rules', []):
                      for x in r.get('domain', []): register(x, 'domain', sid)
                      for x in r.get('domain_suffix', []): register(x, 'suffix', sid)
                      for x in r.get('domain_keyword', []): register(x, 'keyword', sid)

          load_json('s1.json', 'S1')
          load_json('s2.json', 'S2')
          if os.path.exists('s3.list'):
              for line in open('s3.list'):
                  line = line.strip()
                  if not line or line.startswith('#'): continue
                  if line.startswith('+.') or line.startswith('.'): register(line.lstrip('+').lstrip('.'), 'suffix', 'S3')
                  else: register(line, 'domain', 'S3')

          # --- 3. æƒé‡å†³ç­–ä¸åˆæ­¥æ±‡æ€» ---
          candidate_domains = {} # val -> best_type
          for val, info in registry.items():
              if 'S1' in info['sources'] or len(info['sources']) >= 2:
                  # ä¼˜å…ˆçº§: suffix > domain > keyword
                  if 'suffix' in info['types']: candidate_domains[val] = 'domain_suffix'
                  elif 'domain' in info['types']: candidate_domains[val] = 'domain'
                  else: candidate_domains[val] = 'domain_keyword'

          # --- 4. æ™ºèƒ½åˆ†æµåˆ¤å®š (Remote vs Local) ---
          def check_is_local(domain):
              if domain.endswith('.cn'): return True
              # Geosite åŒ¹é…
              parts = domain.split('.')
              for i in range(len(parts)):
                  if '.'.join(parts[i:]) in CN_GEOSITE: return True
              # DNS å½’å±åœ°åˆ¤å®š
              try:
                  ans = resolver.resolve(domain, 'A')
                  ip = ipaddress.ip_address(ans[0].to_text())
                  return any(ip in net for net in CN_NETWORKS)
              except: return False

          print(f'Total candidates: {len(candidate_domains)}. Starting DNS Cleaning...')
          remote_final = {'domain': set(), 'domain_suffix': set(), 'domain_keyword': set()}
          
          with concurrent.futures.ThreadPoolExecutor(max_workers=30) as exe:
              futures = {exe.submit(check_is_local, d): (d, t) for d, t in candidate_domains.items()}
              for f in concurrent.futures.as_completed(futures):
                  d, t = futures[f]
                  if not f.result(): # æ˜¯è¿œç¨‹åŸŸå
                      remote_final[t].add(d)

          # --- 5. æ·±åº¦å»é‡ (å‰”é™¤å·²è¢«åç¼€è¦†ç›–çš„ç²¾ç¡®åŸŸå) ---
          s_list = sorted(list(remote_final['domain_suffix']), key=len)
          filtered_domains = []
          for d in remote_final['domain']:
              if not any(d.endswith('.' + s) or d == s for s in s_list):
                  filtered_domains.append(d)
          
          # --- 6. å¯¼å‡ºç»“æœ ---
          output = {
              'version': 3,
              'rules': [{
                  'domain': sorted(filtered_domains),
                  'domain_suffix': sorted(list(remote_final['domain_suffix'])),
                  'domain_keyword': sorted(list(remote_final['domain_keyword']))
              }]
          }
          with open('fakeip-filter-Remote-DNS.json', 'w') as f:
              json.dump(output, f, indent=2)
          "
          
          # ç¼–è¯‘æˆ SRS
          ./sing-box rule-set compile fakeip-filter-Remote-DNS.json -o fakeip-filter-Remote-DNS.srs

      - name: Process WebRTC & Extra
        run: |
          curl -sL "https://raw.githubusercontent.com/Kris-Channnn/sing-box-proxy/refs/heads/main/webRTC.json" -o raw_webrtc.json
          python3 -c "import json; d=json.load(open('raw_webrtc.json')); open('webRTC.json','w').write(json.dumps({'version': 3, 'rules': d.get('rules', [])}, indent=2))"
          ./sing-box rule-set compile webRTC.json -o webRTC.srs

      - name: Push to Repo
        run: |
          git config --global user.name "github-actions"
          git config --global user.email "actions@github.com"
          rm -f s1.json s2.json s2.srs s3.list raw_webrtc.json sing-box sing-box.tar.gz chnroutes.txt geosite-cn.json
          git add *.json *.srs
          if git diff --staged --quiet; then
            echo "No changes"
          else
            git commit -m "ğŸš€ Sync: Accurate Remote DNS Rules ($(date +'%Y-%m-%d'))"
            git push origin main --force
          fi
