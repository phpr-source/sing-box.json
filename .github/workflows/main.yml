name: Update Comprehensive SRS

on:
  workflow_dispatch:
  schedule:
    - cron: '0 20 * * *' # åŒ—äº¬æ—¶é—´å‡Œæ™¨ 4 ç‚¹è¿è¡Œ
  push:
    paths:
      - '.github/workflows/**'

jobs:
  build:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Install Dependencies
        run: pip install dnspython requests

      - name: Install sing-box
        run: |
          LATEST_TAG=$(curl -s "https://api.github.com/repos/SagerNet/sing-box/releases/latest" | grep -Po '"tag_name": "\K.*?(?=")')
          VERSION_NUM=${LATEST_TAG#v}
          curl -Lo sing-box.tar.gz "https://github.com/SagerNet/sing-box/releases/download/${LATEST_TAG}/sing-box-${VERSION_NUM}-linux-amd64.tar.gz"
          tar -xvf sing-box.tar.gz
          mv sing-box-*/sing-box .
          chmod +x sing-box

      # ----------------------------------------------------------------
      # ä»»åŠ¡ A: Adblock è§„åˆ™æ„å»º (ä¿ç•™ JSON ç”¨äºæ ¡éªŒ)
      # ----------------------------------------------------------------
      - name: Task A - Build Adblock SRS
        run: |
          # ä¸‹è½½å¹¶åœ¨æœ€åä¿ç•™ä¸º Adblock.json
          curl -sL "https://raw.githubusercontent.com/TG-Twilight/AWAvenue-Ads-Rule/main/Filters/AWAvenue-Ads-Rule-Singbox.json" -o Adblock.json
          ./sing-box rule-set compile Adblock.json -o Adblock.srs

      # ----------------------------------------------------------------
      # ä»»åŠ¡ B: FakeIP-Filter æ„å»º - é˜¶æ®µ 1: ä¸‰æºåˆå¹¶
      # ----------------------------------------------------------------
      - name: Task B Stage 1 - Consensus Merge
        run: |
          curl -sL "https://raw.githubusercontent.com/77160860/rule/refs/heads/main/filter.json" -o s1.json
          curl -sL "https://github.com/DustinWin/ruleset_geodata/releases/download/sing-box-ruleset/fakeip-filter.srs" -o s2.srs
          ./sing-box rule-set decompile s2.srs -o s2.json
          curl -sL "https://raw.githubusercontent.com/HenryChiao/mihomo_yamls/refs/heads/main/custom/domain/fake-ip-filter.list" -o s3.list

          python3 -c "
          import json, re, os
          registry = {} 

          def add_to_reg(val, r_type, src):
              if r_type != 'domain_regex': val = val.strip().lower()
              if not val: return
              key = (r_type, val)
              if key not in registry: registry[key] = set()
              registry[key].add(src)

          with open('s1.json', 'r') as f:
              d = json.load(f)
              for r in d.get('rules', []):
                  for k in ['domain', 'domain_suffix', 'domain_keyword', 'domain_regex']:
                      for v in r.get(k, []): add_to_reg(v, k, 'S1')

          with open('s2.json', 'r') as f:
              d = json.load(f)
              for r in d.get('rules', []):
                  for k in ['domain', 'domain_suffix', 'domain_keyword', 'domain_regex']:
                      for v in r.get(k, []): add_to_reg(v, k, 'S2')

          if os.path.exists('s3.list'):
              for line in open('s3.list'):
                  l = line.strip()
                  if not l or l.startswith('#'): continue
                  if l.startswith('.'): add_to_reg(l.lstrip('.'), 'domain_suffix', 'S3')
                  else: add_to_reg(l, 'domain', 'S3')

          final_rules = {'domain': [], 'domain_suffix': [], 'domain_keyword': [], 'domain_regex': []}
          for (r_type, val), sources in registry.items():
              if 'S1' in sources or ('S2' in sources and 'S3' in sources):
                  final_rules[r_type].append(val)

          output = {'version': 3, 'rules': [{k: sorted(v) for k, v in final_rules.items() if v}]}
          with open('fakeip-filter.json', 'w') as f:
              json.dump(output, f, indent=2)
          "
          ./sing-box rule-set compile fakeip-filter.json -o fakeip-filter.srs

      # ----------------------------------------------------------------
      # ä»»åŠ¡ B - é˜¶æ®µ 2: æ·±åº¦æ¸…æ´— (é€»è¾‘ä¿®æ­£ç‰ˆ)
      # ----------------------------------------------------------------
      - name: Task B Stage 2 - Deep Classification
        run: |
          urls=(
            "https://github.com/DustinWin/ruleset_geodata/releases/download/sing-box-ruleset/cn.srs"
            "https://github.com/DustinWin/ruleset_geodata/releases/download/sing-box-ruleset/private.srs"
            "https://raw.githubusercontent.com/YiXuanZX/sing-box-geosite/main/rule/cn-additional-list-clash-classical.srs"
            "https://github.com/DustinWin/ruleset_geodata/releases/download/sing-box-ruleset/microsoft-cn.srs"
            "https://github.com/DustinWin/ruleset_geodata/releases/download/sing-box-ruleset/apple-cn.srs"
            "https://github.com/DustinWin/ruleset_geodata/releases/download/sing-box-ruleset/google-cn.srs"
            "https://github.com/DustinWin/ruleset_geodata/releases/download/sing-box-ruleset/games-cn.srs"
            "https://raw.githubusercontent.com/666OS/rules/release/singbox/Direct.srs" 
          )
          
          for url in "${urls[@]}"; do
            filename=$(basename "$url")
            curl -sL "$url" -o "$filename"
            ./sing-box rule-set decompile "$filename" -o "${filename%.*}.json"
          done

          curl -sL "https://raw.githubusercontent.com/misakaio/chnroutes2/master/chnroutes.txt" -o chnroutes.txt

          python3 -c "
          import json, dns.resolver, ipaddress, concurrent.futures, os, re

          local_exact = set()
          local_suffix = set()
          
          # ================= é…ç½®åŒºåŸŸ =================
          
          # 1. å¼ºåˆ¶ Remote åˆ—è¡¨ (æœ€é«˜ä¼˜å…ˆçº§)
          # å³ä½¿è§£æå‡º CN IP æˆ–åœ¨ç™½åå•ä¸­ï¼Œä¹Ÿå¼ºåˆ¶ä¿ç•™åœ¨ Remote
          # åŒ…å« Joox (è…¾è®¯ç³»è¯¯æ€ä¿®å¤), Disney (dssott), Netflix ç­‰
          force_remote_keywords = [
              'joox', 'sanook', 'netflix', 'spotify', 'hbo', 'disney', 'dssott', 
              'primevideo', 'tiktok', 'hotstar'
          ]

          # 2. å¼ºåˆ¶ Local åˆ—è¡¨ (é˜²æ­¢è¯¯å…¥ Remote)
          # åŒ…å« VoWiFi æ ¸å¿ƒ (3gppnetwork), æ¸¸æˆä¸‹è½½ (steam/nintendo), å¹¿å‘Šè§„åˆ™ (adrules)
          force_local_keywords = [
              'stun', 'ntp', 'time', 'apple', 'gov', 'icloud', 'office', 'msft',
              'mijia', 'mi-', 'xiaomi', 'unionpay', 'jd', 'suning', 'aliyun', 'taobao',
              'linksys', 'router', 'tplink', 'asus', 'tplogin', 'miwifi', 'tendawifi', 
              'tplinkcloud', 'belkin', 'wemo', 'mercury', 'synology', 'qnap',
              '3gppnetwork', 'steamcontent', 'nintendo', 'playstation', 'xbox', 'games',
              'volte', 'vowifi', 'ims', 'mms'
          ]
          
          force_local_suffixes = {
              'direct', 'lan', 'local', 'home.arpa', 'pi-hole', 'speedtest.net', 
              'adrules.top'
          }

          # ================= é€»è¾‘åŒºåŸŸ =================

          def load_white(path):
              if not os.path.exists(path): return
              try:
                  with open(path, 'r') as f:
                      d = json.load(f)
                      for r in d.get('rules', []):
                          for x in r.get('domain', []): local_exact.add(x.lower())
                          for x in r.get('domain_suffix', []): local_suffix.add(x.lower())
              except: pass

          # åŠ è½½ä¸‹è½½çš„ç™½åå•
          # æ’é™¤å½“å‰ä»»åŠ¡ç”Ÿæˆçš„ä¸­é—´æ–‡ä»¶
          json_files = [f for f in os.listdir('.') if f.endswith('.json') and f not in ['fakeip-filter.json', 's1.json', 's2.json', 'Adblock.json']]
          for p in json_files:
              load_white(p)

          cn_nets = [ipaddress.ip_network(l.strip()) for l in open('chnroutes.txt') if l.strip() and not l.startswith('#')]
          resolver = dns.resolver.Resolver()
          resolver.nameservers = ['223.5.5.5', '119.29.29.29']
          resolver.timeout = 2.0

          def is_local_dns(domain):
              d = domain.lower().strip('.')
              
              # A. ä¼˜å…ˆçº§ 1: å¼ºåˆ¶ Remote (ä¿æŠ¤ Joox/Disney)
              # å¦‚æœåŒ¹é…ï¼Œè¿”å› False (ä»£è¡¨ä¸æ˜¯ Localï¼Œå³ä¿ç•™åœ¨ Remote)
              if any(k in d for k in force_remote_keywords): return False

              # B. ä¼˜å…ˆçº§ 2: å¼ºåˆ¶ Local (å¤„ç† 3gpp/Steam)
              if any(k in d for k in force_local_keywords): return True
              if any(d.endswith(s) for s in force_local_suffixes): return True
              
              # C. ä¼˜å…ˆçº§ 3: ç™½åå• (Direct/CN åˆ—è¡¨)
              if d.endswith('.cn'): return True
              if d in local_exact: return True
              parts = d.split('.')
              for i in range(len(parts)):
                  if '.'.join(parts[i:]) in local_suffix: return True
              
              # D. ä¼˜å…ˆçº§ 4: DNS æ¢æµ‹
              try:
                  ans = resolver.resolve(d, 'A')
                  for ip in ans:
                      ip_obj = ipaddress.ip_address(ip.to_text())
                      if any(ip_obj in net for net in cn_nets) or ip_obj.is_private: return True
              except (dns.resolver.NXDOMAIN, dns.resolver.NoAnswer):
                  # åŸŸåä¸å­˜åœ¨ï¼Œé€šå¸¸è®¤ä¸ºæ˜¯å†…ç½‘åŸŸåæˆ–æ­»åŸŸåï¼Œä¸æ”¾å…¥ Remote
                  return True
              except:
                  # è§£æè¶…æ—¶ï¼Œä¿å®ˆå¤„ç†ï¼Œè®¤ä¸ºæ˜¯ Local
                  return True
              return False

          with open('fakeip-filter.json', 'r') as f:
              source = json.load(f)

          remote_rules = {'domain': [], 'domain_suffix': [], 'domain_keyword': [], 'domain_regex': []}
          rules_obj = source['rules'][0]
          
          # å¤„ç† Regex å’Œ Keyword
          # é€»è¾‘ï¼šåªè¦ä¸æ˜¯å¼ºåˆ¶ Localï¼Œä¸”ä¸åŒ…å«åœ¨ç™½åå•ç‰¹å¾ä¸­ï¼Œåˆ™ä¿ç•™
          # ä¿®æ­£ï¼šå¢åŠ  force_remote_keywords æ£€æŸ¥ï¼Œé˜²æ­¢è¯¯åˆ 
          def is_local_pattern(pattern):
              p_low = pattern.lower()
              # 1. å¦‚æœåŒ…å« Joox ç­‰å…³é”®å­—ï¼Œå¼ºåˆ¶è®¤ä¸ºæ˜¯ Remote Pattern (è¿”å› False)
              if any(k in p_low for k in force_remote_keywords): return False 
              
              # 2. å¦‚æœåŒ…å« Local å…³é”®å­—ï¼Œå¼ºåˆ¶è®¤ä¸ºæ˜¯ Local
              if any(k in p_low for k in force_local_keywords): return True
              if any(s in p_low for s in force_local_suffixes): return True
              if '.cn' in p_low: return True
              
              # 3. ç®€å•æ£€æŸ¥ç™½åå•åç¼€ (é˜²æ­¢ .com.cn æ­£åˆ™è¢«è¯¯æ€ï¼Œä½†é€šå¸¸æ­£åˆ™æ¯”è¾ƒå¤æ‚ï¼Œè¿™é‡Œåªåšç®€å•åŒ¹é…)
              for s in local_suffix:
                  if s in p_low: return True
              return False

          for k in rules_obj.get('domain_keyword', []):
              if not is_local_pattern(k): remote_rules['domain_keyword'].append(k)
          for r in rules_obj.get('domain_regex', []):
              if not is_local_pattern(r): remote_rules['domain_regex'].append(r)

          # å¤„ç† Domain å’Œ Suffix
          to_check = []
          for d in rules_obj.get('domain', []): to_check.append((d, 'domain'))
          for d in rules_obj.get('domain_suffix', []): to_check.append((d, 'domain_suffix'))

          with concurrent.futures.ThreadPoolExecutor(max_workers=30) as exe:
              futures = {exe.submit(is_local_dns, item[0]): item for item in to_check}
              for f in concurrent.futures.as_completed(futures):
                  domain, r_type = futures[f]
                  # åªæœ‰å½“ is_local_dns è¿”å› False æ—¶ï¼Œæ‰åŠ å…¥ Remote åˆ—è¡¨
                  if not f.result():
                      remote_rules[r_type].append(domain)

          # æ·±åº¦å»é‡ï¼šå¦‚æœ domain_suffix å·²ç»åŒ…å« google.comï¼Œåˆ™ä¸éœ€è¦å†å­˜ www.google.com
          s_set = set(remote_rules['domain_suffix'])
          remote_rules['domain'] = [d for d in remote_rules['domain'] if not any(d.endswith('.' + s) or d == s for s in s_set)]

          with open('fakeip-filter-Remote-DNS.json', 'w') as f:
              json.dump({'version': 3, 'rules': [{k: sorted(v) for k, v in remote_rules.items() if v}]}, f, indent=2)
          "
          ./sing-box rule-set compile fakeip-filter-Remote-DNS.json -o fakeip-filter-Remote-DNS.srs

      # ----------------------------------------------------------------
      # ä»»åŠ¡ C: WebRTC å¤„ç†ä¸æœ€ç»ˆæ¨é€
      # ----------------------------------------------------------------
      - name: Stage 3 - Finalize
        run: |
          curl -sL "https://raw.githubusercontent.com/Kris-Channnn/sing-box-proxy/refs/heads/main/webRTC.json" -o raw_webrtc.json
          python3 -c "import json; d=json.load(open('raw_webrtc.json')); open('webRTC.json','w').write(json.dumps({'version': 3, 'rules': d.get('rules', [])}, indent=2))"
          ./sing-box rule-set compile webRTC.json -o webRTC.srs

          git config --global user.name "github-actions"
          git config --global user.email "actions@github.com"
          
          # æ¸…ç†ä¸´æ—¶æ–‡ä»¶ï¼Œç‰¹æ„æ’é™¤ Adblock.json å’Œ Adblock.srs
          find . -maxdepth 1 -type f -name "*.json" ! -name "fakeip-filter.json" ! -name "fakeip-filter-Remote-DNS.json" ! -name "webRTC.json" ! -name "Adblock.json" -delete
          find . -maxdepth 1 -type f -name "*.srs" ! -name "fakeip-filter.srs" ! -name "fakeip-filter-Remote-DNS.srs" ! -name "webRTC.srs" ! -name "Adblock.srs" -delete
          rm -f s3.list chnroutes.txt sing-box sing-box.tar.gz
          
          git add *.json *.srs
          if git diff --staged --quiet; then
            echo "No changes"
          else
            git commit -m "ğŸš€ Sync: Adblock JSON/SRS & Logic Fixes (Joox/Disney/Regex) ($(date +'%Y-%m-%d'))"
            git push origin main --force
          fi
