name: Update Comprehensive SRS

on:
  workflow_dispatch:
  schedule:
    - cron: '0 20 * * *' 
  push:
    paths:
      - 'fakeip-filter-Remote-DNS.json'
      - '.github/workflows/**'

jobs:
  build:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Install Dependencies
        run: pip install dnspython requests

      - name: Install sing-box
        run: |
          LATEST_TAG=$(curl -s "https://api.github.com/repos/SagerNet/sing-box/releases/latest" | grep -Po '"tag_name": "\K.*?(?=")')
          VERSION_NUM=${LATEST_TAG#v}
          curl -Lo sing-box.tar.gz "https://github.com/SagerNet/sing-box/releases/download/${LATEST_TAG}/sing-box-${VERSION_NUM}-linux-amd64.tar.gz"
          tar -xvf sing-box.tar.gz
          mv sing-box-*/sing-box .
          chmod +x sing-box

      - name: Advanced Consensus Merge & Smart Classification
        run: |
          curl -sL "https://raw.githubusercontent.com/77160860/rule/refs/heads/main/filter.json" -o s1.json
          curl -sL "https://github.com/DustinWin/ruleset_geodata/releases/download/sing-box-ruleset/fakeip-filter.srs" -o s2.srs
          ./sing-box rule-set decompile s2.srs -o s2.json
          curl -sL "https://raw.githubusercontent.com/HenryChiao/mihomo_yamls/refs/heads/main/custom/domain/fake-ip-filter.list" -o s3.list
          
          curl -sL "https://raw.githubusercontent.com/misakaio/chnroutes2/master/chnroutes.txt" -o chnroutes.txt
          curl -sL "https://raw.githubusercontent.com/MetaCubeX/meta-rules-dat/sing/geo/geosite/cn.json" -o geosite-cn.json

          python3 -c "
          import json, re, os, dns.resolver, ipaddress, concurrent.futures

          # --- 1. é…ç½®ä¸èµ„æºåŠ è½½ ---
          registry = {}
          LAN_SUFFIXES = {'.lan', '.local', '.home.arpa', '.internal', '.localdomain', 'localhost'}
          # ç¦æ­¢å…³è”çš„å…³é”®è¯ï¼ˆä¿æŠ¤åå•ï¼‰ï¼šå³ä½¿ remote åˆ—è¡¨ä¸­å‡ºç°äº†ç›¸å…³åŸŸåï¼Œä¹Ÿä¸å…è®¸å…³è”åˆ°è¿™äº›æœåŠ¡
          PROTECTED_KEYWORDS = {'qq', 'tencent', 'alibaba', 'aliyun', 'baidu', 'jd', 'mi', 'xiaomi', 'localhost', '127-0-0-1'}
          
          CN_NETWORKS = [ipaddress.ip_network(l.strip()) for l in open('chnroutes.txt') if l.strip() and not l.startswith('#')]
          
          CN_GEOSITE = set()
          try:
              with open('geosite-cn.json', 'r') as f:
                  g = json.load(f)
                  for r in g.get('rules', []):
                      for k in ['domain', 'domain_suffix']:
                          for d in r.get(k, []): CN_GEOSITE.add(d.lower())
          except: pass

          resolver = dns.resolver.Resolver()
          resolver.nameservers = ['8.8.8.8', '1.1.1.1']
          resolver.timeout = 1.5

          def register(val, r_type, source_id):
              val = val.strip().lower()
              if not val or len(val) < 3 or ' ' in val: return
              if any(val.endswith(s) or val == s.strip('.') for s in LAN_SUFFIXES): return
              if val not in registry: registry[val] = {'sources': set(), 'types': set()}
              registry[val]['sources'].add(source_id)
              registry[val]['types'].add(r_type)

          # åŠ è½½æº
          load_json = lambda path, sid: [ ( [register(x, 'domain', sid) for x in r.get('domain', [])], 
                                         [register(x, 'suffix', sid) for x in r.get('domain_suffix', [])],
                                         [register(x, 'keyword', sid) for x in r.get('domain_keyword', [])] ) 
                                       for r in json.load(open(path)).get('rules', [])] if os.path.exists(path) else None
          
          load_json('s1.json', 'S1')
          load_json('s2.json', 'S2')
          if os.path.exists('s3.list'):
              for line in open('s3.list'):
                  line = line.strip()
                  if not line or line.startswith('#'): continue
                  if line.startswith('+.') or line.startswith('.'): register(line.lstrip('+').lstrip('.'), 'suffix', 'S3')
                  else: register(line, 'domain', 'S3')

          # æƒé‡å†³ç­–
          candidate_domains = {}
          for val, info in registry.items():
              if 'S1' in info['sources'] or len(info['sources']) >= 2:
                  if 'suffix' in info['types']: candidate_domains[val] = 'domain_suffix'
                  elif 'domain' in info['types']: candidate_domains[val] = 'domain'
                  else: candidate_domains[val] = 'domain_keyword'

          # --- 2. åŸºç¡€åˆ†æµåˆ¤å®š ---
          def check_is_local(domain):
              if domain.endswith('.cn'): return True
              parts = domain.split('.')
              for i in range(len(parts)):
                  if '.'.join(parts[i:]) in CN_GEOSITE: return True
              try:
                  ans = resolver.resolve(domain, 'A')
                  ip = ipaddress.ip_address(ans[0].to_text())
                  return any(ip in net for net in CN_NETWORKS)
              except: return False

          print('Step 1: Basic Cleaning...')
          remote_pool = {} # domain -> type
          local_pool = {}  # domain -> type
          
          with concurrent.futures.ThreadPoolExecutor(max_workers=30) as exe:
              futures = {exe.submit(check_is_local, d): (d, t) for d, t in candidate_domains.items()}
              for f in concurrent.futures.as_completed(futures):
                  d, t = futures[f]
                  if not f.result(): remote_pool[d] = t
                  else: local_pool[d] = t

          # --- 3. åŒæœåŠ¡å…³è”é€»è¾‘ (The Joox/Sanook Logic) ---
          print('Step 2: Service Association Analysis...')
          # æå– Remote åˆ—è¡¨ä¸­çš„æ ¸å¿ƒç‰¹å¾è¯
          remote_keywords = set()
          for d in remote_pool.keys():
              parts = d.split('.')
              # æå–ä¸»åŸŸåä¸»ä½“ï¼Œä¾‹å¦‚ api.joox.com -> joox
              if len(parts) >= 2:
                  main_part = parts[-2]
                  if len(main_part) > 3 and main_part not in PROTECTED_KEYWORDS:
                      remote_keywords.add(main_part)

          # æ‰«æ Local åˆ—è¡¨ï¼Œå¦‚æœåŒ…å«è¿œç¨‹ç‰¹å¾è¯ï¼Œåˆ™ç§»åŠ¨åˆ° Remote
          upgraded_count = 0
          local_keys = list(local_pool.keys())
          for d in local_keys:
              # å¿…é¡»ä¸åœ¨ä¿æŠ¤åå•å†…ï¼Œä¸”åŒ…å«è¿œç¨‹ç‰¹å¾è¯
              if not any(pk in d for pk in PROTECTED_KEYWORDS):
                  if any(rk in d for rk in remote_keywords):
                      remote_pool[d] = local_pool.pop(d)
                      upgraded_count += 1
          print(f'Association complete. {upgraded_count} domains upgraded to Remote.')

          # --- 4. æ·±åº¦å»é‡ä¸å¯¼å‡º ---
          remote_final = {'domain': set(), 'domain_suffix': set(), 'domain_keyword': set()}
          for d, t in remote_pool.items():
              # å°† domain_suffix æ‹†åˆ†ä¸ºçœŸæ­£çš„ç±»å‹
              if t == 'domain_suffix': remote_final['domain_suffix'].add(d)
              elif t == 'domain': remote_final['domain'].add(d)
              else: remote_final['domain_keyword'].add(d)

          s_list = sorted(list(remote_final['domain_suffix']), key=len)
          filtered_domain = [d for d in remote_final['domain'] if not any(d.endswith('.' + s) or d == s for s in s_list)]
          
          output = {
              'version': 3,
              'rules': [{
                  'domain': sorted(filtered_domain),
                  'domain_suffix': sorted(list(remote_final['domain_suffix'])),
                  'domain_keyword': sorted(list(remote_final['domain_keyword']))
              }]
          }
          json.dump(output, open('fakeip-filter-Remote-DNS.json', 'w'), indent=2)
          "
          ./sing-box rule-set compile fakeip-filter-Remote-DNS.json -o fakeip-filter-Remote-DNS.srs

      - name: Process WebRTC & Extra
        run: |
          curl -sL "https://raw.githubusercontent.com/Kris-Channnn/sing-box-proxy/refs/heads/main/webRTC.json" -o raw_webrtc.json
          python3 -c "import json; d=json.load(open('raw_webrtc.json')); open('webRTC.json','w').write(json.dumps({'version': 3, 'rules': d.get('rules', [])}, indent=2))"
          ./sing-box rule-set compile webRTC.json -o webRTC.srs

      - name: Push to Repo
        run: |
          git config --global user.name "github-actions"
          git config --global user.email "actions@github.com"
          rm -f s1.json s2.json s2.srs s3.list raw_webrtc.json sing-box sing-box.tar.gz chnroutes.txt geosite-cn.json
          git add *.json *.srs
          if git diff --staged --quiet; then
            echo "No changes"
          else
            git commit -m "ğŸš€ Sync: Accurate Remote DNS with Service Association ($(date +'%Y-%m-%d'))"
            git push origin main --force
          fi
