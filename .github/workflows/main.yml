name: Update Comprehensive SRS

on:
  workflow_dispatch:
  schedule:
    - cron: '0 20 * * *' # åŒ—äº¬æ—¶é—´å‡Œæ™¨ 4 ç‚¹è¿è¡Œ (UTC 20:00)
  push:
    paths:
      - 'fakeip-filter-Remote-DNS.json'
      - '.github/workflows/**'

jobs:
  build:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
          cache: 'pip'

      - name: Install Dependencies
        run: |
          pip install dnspython requests

      - name: Install sing-box
        run: |
          LATEST_TAG=$(curl -s "https://api.github.com/repos/SagerNet/sing-box/releases/latest" | grep -Po '"tag_name": "\K.*?(?=")')
          VERSION_NUM=${LATEST_TAG#v}
          curl -Lo sing-box.tar.gz "https://github.com/SagerNet/sing-box/releases/download/${LATEST_TAG}/sing-box-${VERSION_NUM}-linux-amd64.tar.gz"
          tar -xvf sing-box.tar.gz
          mv sing-box-*/sing-box .
          chmod +x sing-box

      # ----------------------------------------------------------------
      # é˜¶æ®µ 1: ç”Ÿæˆ fakeip-filter.json (ä½ çš„åŸå§‹é€»è¾‘)
      # ----------------------------------------------------------------
      - name: Advanced Consensus Merge (FakeIP)
        run: |
          # 1. ä¸‹è½½æº
          curl -sL "https://raw.githubusercontent.com/77160860/rule/refs/heads/main/filter.json" -o s1.json
          curl -sL "https://github.com/DustinWin/ruleset_geodata/releases/download/sing-box-ruleset/fakeip-filter.srs" -o s2.srs
          ./sing-box rule-set decompile s2.srs -o s2.json
          curl -sL "https://raw.githubusercontent.com/HenryChiao/mihomo_yamls/refs/heads/main/custom/domain/fake-ip-filter.list" -o s3.list

          python3 -c "
          import json, re, os

          registry = {}

          def register(val, r_type, source_id):
              val = val.strip().lower()
              if not val or len(val) < 3 or ' ' in val or '/' in val or ':' in val: return
              if re.match(r'^\d{1,3}(\.\d{1,3}){3}$', val): return
              
              if val not in registry:
                  registry[val] = {'sources': set(), 'types': set()}
              registry[val]['sources'].add(source_id)
              registry[val]['types'].add(r_type)

          def load_json(path, sid):
              if not os.path.exists(path): return
              with open(path, 'r') as f:
                  data = json.load(f)
                  for r in data.get('rules', []):
                      for x in r.get('domain', []): register(x, 'domain', sid)
                      for x in r.get('domain_suffix', []): register(x, 'suffix', sid)
                      for x in r.get('domain_keyword', []): register(x, 'keyword', sid)
                      for x in r.get('domain_regex', []): register(x, 'regex', sid)

          load_json('s1.json', 'S1')
          load_json('s2.json', 'S2')

          if os.path.exists('s3.list'):
              with open('s3.list', 'r') as f:
                  for line in f:
                      line = line.strip()
                      if not line or line.startswith('#'): continue
                      if line.startswith('+.') or line.startswith('.'):
                          register(re.sub(r'^[+.]+', '', line), 'suffix', 'S3')
                      else:
                          register(line, 'domain', 'S3')

          final_rules = {'domain': [], 'domain_suffix': [], 'domain_keyword': [], 'domain_regex': []}
          
          for val, info in registry.items():
              if 'S1' in info['sources'] or len(info['sources']) >= 2:
                  if 'suffix' in info['types']: final_rules['domain_suffix'].append(val)
                  elif 'domain' in info['types']: final_rules['domain'].append(val)
                  elif 'keyword' in info['types']: final_rules['domain_keyword'].append(val)
                  elif 'regex' in info['types']: final_rules['domain_regex'].append(val)

          s_set = set(final_rules['domain_suffix'])
          final_rules['domain'] = [d for d in final_rules['domain'] if not any(d.endswith('.' + s) or d == s for s in s_set)]

          output = {'version': 2, 'rules': [{k: sorted(v) for k, v in final_rules.items() if v}]}
          with open('fakeip-filter.json', 'w') as f:
              json.dump(output, f, indent=2)
          "
          ./sing-box rule-set compile fakeip-filter.json -o fakeip-filter.srs

      # ----------------------------------------------------------------
      # é˜¶æ®µ 2: æ™ºèƒ½åˆ†æµæ¸…æ´— (Remote vs Local)
      # ----------------------------------------------------------------
      - name: Classify Domains (Three-Layer Filter)
        run: |
          # 1. ä¸‹è½½è¾…åŠ©æ•°æ®ï¼šCN IPæ®µ (chnroute) å’Œ Geosite CN åˆ—è¡¨
          curl -sL "https://raw.githubusercontent.com/misakaio/chnroutes2/master/chnroutes.txt" -o chnroutes.txt
          curl -sL "https://raw.githubusercontent.com/MetaCubeX/meta-rules-dat/sing/geo/geosite/cn.json" -o geosite-cn.json

          # 2. è¿è¡Œåˆ†ç±»è„šæœ¬
          python3 -c "
          import json
          import dns.resolver
          import ipaddress
          import requests
          import concurrent.futures

          SOURCE_FILE = 'fakeip-filter.json'
          OUTPUT_REMOTE = 'fakeip-filter-Remote-DNS.json'
          CHNROUTE_FILE = 'chnroutes.txt'
          GEOSITE_CN_FILE = 'geosite-cn.json'

          # --- åŠ è½½èµ„æº ---
          print('Loading resources...')
          
          # åŠ è½½ CN IP æ®µ (æ”¹ä¸ºäºŒåˆ†æŸ¥æ‰¾æˆ–ç›´æ¥éå†ï¼Œè€ƒè™‘åˆ°Github Actionæ€§èƒ½ï¼Œç›´æ¥åŠ è½½æˆå¯¹è±¡åˆ—è¡¨)
          cn_networks = []
          with open(CHNROUTE_FILE, 'r') as f:
              for line in f:
                  if line.strip() and not line.startswith('#'):
                      cn_networks.append(ipaddress.ip_network(line.strip()))

          # åŠ è½½ Geosite CN åŸŸå (ä½œä¸ºç™½åå•é˜²æ­¢CDNè¯¯åˆ¤)
          cn_domains_whitelist = set()
          try:
              with open(GEOSITE_CN_FILE, 'r') as f:
                  geo_data = json.load(f)
                  for rule in geo_data.get('rules', []):
                      for d in rule.get('domain', []): cn_domains_whitelist.add(d)
                      for d in rule.get('domain_suffix', []): cn_domains_whitelist.add(d)
          except Exception as e:
              print(f'Warning: Failed to load Geosite CN: {e}')

          # é…ç½® DNS (ä½¿ç”¨ Google/Cloudflare DNS æ··åˆ)
          resolver = dns.resolver.Resolver()
          resolver.nameservers = ['8.8.8.8', '1.1.1.1']
          resolver.timeout = 2.0
          resolver.lifetime = 2.0

          # --- æ ¸å¿ƒå‡½æ•° ---
          def is_ip_in_cn(ip_str):
              try:
                  ip = ipaddress.ip_address(ip_str)
                  for net in cn_networks:
                      if ip in net:
                          return True
              except:
                  pass
              return False

          def is_domain_cn_static(domain):
              # 1. åç¼€åˆ¤æ–­
              if domain.endswith('.cn'): return True
              # 2. ç™½åå•åˆ¤æ–­ (ç®€å•åç¼€åŒ¹é…)
              domain_parts = domain.split('.')
              for i in range(len(domain_parts)):
                  sub = '.'.join(domain_parts[i:])
                  if sub in cn_domains_whitelist:
                      return True
              return False

          def resolve_and_check(domain):
              # è¿”å› (domain, is_local)
              if is_domain_cn_static(domain):
                  return (domain, True) # é™æ€è§„åˆ™å‘½ä¸­ Local
              
              try:
                  # å°è¯•è§£æ IP
                  answers = resolver.resolve(domain, 'A')
                  ip = answers[0].to_text()
                  if is_ip_in_cn(ip):
                      return (domain, True) # åŠ¨æ€è§£æä¸º CN IP
                  else:
                      return (domain, False) # åŠ¨æ€è§£æä¸º å¤–å›½ IP
              except:
                  # è§£æå¤±è´¥ (NXDOMAIN, Timeout)
                  # ç­–ç•¥ï¼šå¦‚æœè§£æä¸å‡ºæ¥ï¼Œå¤§æ¦‚ç‡æ˜¯è¢«å¢™æˆ–ä¸å­˜åœ¨ï¼Œå½’ç±»ä¸º Remote æ›´å®‰å…¨
                  return (domain, False)

          # --- ä¸»æµç¨‹ ---
          with open(SOURCE_FILE, 'r') as f:
              data = json.load(f)
          
          # æå– fakeip-filter ä¸­çš„æ‰€æœ‰åŸŸåï¼ˆæ‰å¹³åŒ–å¤„ç†ï¼‰
          all_domains = set()
          for r in data.get('rules', []):
              for k in ['domain', 'domain_suffix', 'domain_keyword']: # å¿½ç•¥ Regex
                  for d in r.get(k, []):
                      all_domains.add(d)

          print(f'Processing {len(all_domains)} unique domains...')
          
          remote_list = []
          
          # å¹¶å‘å¤„ç†ä»¥åŠ å¿«é€Ÿåº¦
          with concurrent.futures.ThreadPoolExecutor(max_workers=20) as executor:
              future_to_domain = {executor.submit(resolve_and_check, d): d for d in all_domains}
              for future in concurrent.futures.as_completed(future_to_domain):
                  domain, is_local = future.result()
                  if not is_local:
                      remote_list.append(domain)

          # --- è¾“å‡º ---
          # ä¿æŒ sing-box æ ¼å¼
          output_data = {
              'version': 2,
              'rules': [{'domain_suffix': sorted(remote_list)}] # ç»Ÿä¸€ä½œä¸º suffix å¤„ç†ä»¥è¦†ç›–å­åŸŸå
          }
          
          print(f'Total Remote Domains Identified: {len(remote_list)}')
          
          with open(OUTPUT_REMOTE, 'w') as f:
              json.dump(output_data, f, indent=2)
          "
          
          # ç¼–è¯‘ Remote åˆ—è¡¨
          ./sing-box rule-set compile fakeip-filter-Remote-DNS.json -o fakeip-filter-Remote-DNS.srs

      # ----------------------------------------------------------------
      # é˜¶æ®µ 3: WebRTC & Push
      # ----------------------------------------------------------------
      - name: Process WebRTC
        run: |
          curl -sL "https://raw.githubusercontent.com/Kris-Channnn/sing-box-proxy/refs/heads/main/webRTC.json" -o raw_webrtc.json
          python3 -c "import json; f=open('raw_webrtc.json','r'); d=json.load(f); f.close(); open('webRTC.json','w').write(json.dumps({'version': 2, 'rules': d.get('rules', [])}, indent=2))"
          ./sing-box rule-set compile webRTC.json -o webRTC.srs

      - name: Git Push
        run: |
          git config --global user.name "github-actions"
          git config --global user.email "actions@github.com"
          # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
          rm -f s1.json s2.json s2.srs s3.list raw_webrtc.json sing-box sing-box.tar.gz chnroutes.txt geosite-cn.json
          
          git add *.json *.srs
          
          # ä»…å½“æœ‰å˜åŒ–æ—¶æ‰æäº¤
          if git diff --staged --quiet; then
            echo "No changes to commit."
          else
            git commit -m "ğŸš€ Sync: Smart Classification ($(date +'%Y-%m-%d'))"
            git push origin main --force
          fi
